
I'd like for the text file reading to not happen in a 2nd docker exec.
Suppose I injected this script into the tar file...


readonly TMP_DIR=$(mktemp -d /tmp/XXXXXX)
remove_tmp_dir() { rm -rf "${TMP_DIR}" > /dev/null; }
trap remove_tmp_dir EXIT

cd /sandbox
./cyber-dojo.sh \
  >${TMP_DIR}/stdout \
  2>${TMP_DIR}/stderr

echo $? > ${TMP_DIR}/status
truncate --size=50K ${TMP_DIR}/stdout
truncate --size=50K ${TMP_DIR}/stderr
#1
jq -n --arg stdout --arg stderr --arg status \
  "$(< ${TMP}/stdout)" \
  "$(< ${TMP}/stderr)" \
  "$(< ${TMP}/status)" \
  '{stdout:$stdout, stderr:$stderr, status:$status}'

Then back in the runner service code, I read stdin and parse it as json.
This would allow me to insert another script at #1 which gathers the
required info on generated files. These would also be truncated and added
to the json.

Truncation. If I want to truncate to 50K then I need to truncate to 50K+1
This is so that inside the runner I can tell.
If it is 50K+1 truncate it by 1 byte and mark it as truncated.

Better, truncate stdout/stderr at creation:
https://stackoverflow.com/questions/61794952

cd /sandbox
./cyber-dojo.sh \
  >  >(head -c$((50*1024+1)) > "${TMP_DIR}/stdout") \
  2> >(head -c$((50*1024+1)) > "${TMP_DIR}/stderr")

So...
#---------------------------------------------------------------

readonly TMP_DIR=$(mktemp -d /tmp/XXXXXX)
remove_tmp_dir() { rm -rf "${TMP_DIR}" > /dev/null; }
trap remove_tmp_dir EXIT

cd /sandbox
./cyber-dojo.sh \
   > >(head -c$((50*1024+1)) > "${TMP_DIR}/stdout") \
  2> >(head -c$((50*1024+1)) > "${TMP_DIR}/stderr")

echo $? > ${TMP_DIR}/status

#1

jq -n \
  --arg stdout \
  --arg stderr \
  --arg status \
  "$(< ${TMP}/stdout)" \
  "$(< ${TMP}/stderr)" \
  "$(< ${TMP}/status)" \
  '{stdout:$stdout, stderr:$stderr, status:$status}'

#---------------------------------------------------------------

This relies on being to use a large bash command line
Check on images...
The limit for an indivual argument is from <limits.h>
https://unix.stackexchange.com/questions/120642

Debian (gcc_assert)
$ getconf ARG_MAX
2097152
==2048K

Ubuntu (clang_assert)
$ getconf ARG_MAX
2097152
==2048K

Alpine (csharp_nunit)
$ getconf ARG_MAX
131072
==
128K

#---------------------------------------------------------------
echo xxxx > x.txt
echo yyyy > y.txt
fn(){ echo "x.txt"; echo "y.txt"; }
fn | xargs -L 1 -I {} jq -sR --arg key {} '{ ($key): .}' {} | jq -s 'add'
{
  "x.txt": "xxxx\n",
  "y.txt": "yyyy\n"
}

This doesn't work on Alpine.
Looks like its xargs lacks the [-L 1]
Need to do
$ apk add --update findutils

Long xargs options are...
-L, --max-lines=MAX-LINES    use at most MAX-LINES non-blank input lines per command line

-I R                         same as --replace=R
-i, --replace[=R]            replace R in INITIAL-ARGS with names read
                                 from standard input; if R is unspecified,
                                 assume {}

Long jq options are...
-s, --slurp
-R, --raw-input


Need to put them into a sub hash...

echo xxxx > x.txt
echo yyyy > y.txt
fn(){ echo "x.txt"; echo "y.txt"; }
fn | xargs --max-lines=1 --replace={} \
       jq --slurp --raw-input --arg key {} '{ ($key): .}' {} \
   | jq --slurp 'reduce .[] as $item ({}; . * $item)'

{
  "files": {
    "x.txt": "xxx\n",
    "y.txt": "yyy\n"
  }
}

Better to keep the two json files separate; that way
whether the text-file harvesting happens can become
an option.


jq -n \
  --arg stdout \
  --arg stderr \
  --arg status \
  "$(< ${TMP}/stdout)" \
  "$(< ${TMP}/stderr)" \
  "$(< ${TMP}/status)" \
  '{stdout:$stdout, stderr:$stderr, status:$status}' \
  > sss.json

echo xxxx > x.txt
echo yyyy > y.txt
fn(){ echo "x.txt"; echo "y.txt"; }
fn | xargs --max-lines=1 --replace={} \
       jq --slurp --raw-input --arg key {} '{ ($key): .}' {} \
   | jq --slurp 'reduce .[] as $item ({}; . * $item)' \
   > files.json

jq --slurp '.[0] * .[1]' sss.json files.json

{
  "stdout": "dfgdfgdfgdfgdfg",
  "stderr": "dfgsdfsdfds",
  "status": "42",
  "files": {
    "x.txt": "xxx\n",
    "y.txt": "yyy\n"
  }
}
