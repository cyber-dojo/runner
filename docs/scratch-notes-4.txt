
Not using json. Using plain tar pipes.
Checked whether compression made it faster.
No detectable difference.

# TODO: 0. error logging for TrafficLight
# TODO: 1. cache for rag-lambdas. In place. Loggings needs adding.
# TODO: 2. only gather text files if manifest['hidden_filenames'] is set?

# TODO: test time-outs gather stdout (viz trap handler fires) for Debian+Alpine (do in injected bash?)

# TODO: add test for cyber-dojo killing its own main.sh process. I think it will cause exceptions in Ruby

# TODO: add test for cyber-dojo.sh writing to stdout but without newlines.
        I think trap handler needs to flush >stdout pipe and 2>stderr pipe.

# TODO: test for cyber-dojo.sh killing everything under sandbox (including itself). DONE. 62C

# TODO: add tmp-dir for home/sandbox.
# TODO: make container --readonly. Check on all LTFs
# TODO: split docker-run into run+exec as before ready for container cache?
# TODO: setup stderr pipe in main Process.spawn() and log stderr-string if non empty
# TODO: capture status of Process.spawn and log that too.
# TODO: drop jq and xargs installs in image_dockerfile_augmenter

Thinking about container-caches.
--------------------------------
Suppose a container was created with an entrypoint whose script
1) waited for a signal
2) untarred tgz on stdin
3) ran /tmp/main.sh
Now cache could create such container.
And request could get container from cache and docker-exec it
Good step would be to re-split the docker-run into a docker-run and
a docker-exec again. Look at older commit
   1. create_container(id, image_name)
      this is a docker run (did a sleep before)
   2. run(files, max_seconds)
      this is a docker exec wrapped in a Timeout.
Now, cache holds containers keyed on image_name.
When cache gives out 1 container (from the cache) it makes an async
http post to runner say it just used 1 cached container.
https://github.com/gworley3/httpray
https://medium.com/adstage-engineering/httpray-for-your-http-requests-in-ruby-7783f85436f7
A runner replica would receive the post, and would create zero or
more new containers to get it to its cache limit. You could
send out N posts to hit more replicas. This might be useful
if payload contained info from sender, eg rate of emptying/filling the cache.



readonly containers
-------------------
Further, if the docker-run used --read-only it would mean
all LTFs were using /tmp and /sandbox only.
That would even make it possible to recycle containers.
You'd only really need to clear out /tmp and /sandbox.

They should be readonly anyway...
What happens to tests with --read-only added...
Only 2 failures
TrafficLightTest
9DB Ubuntu L23
9DD Ubuntu L41
Access to the path /home/sandbox/.mono is denied.
Need to make another tmp-fs for /home/sandbox
TMP_FS_HOME_DIR = "--tmpfs /home/sandbox:exec,size=50M,uid=#{UID},gid=#{GID}"
--read-only
And all pass :-)
Need to try on all LTFs
