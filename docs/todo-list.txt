
BIGGER
======
Speedup - deployment stages....
 - cyber-dojo.sh cat stdout/stderr to files (and echo those back to stdout/stderr)
 - cyber-dojo.sh write sss to tar file and tgz that.
 - main.sh pipe the echo_textfilenames script into stdin and extract it then run it
 - echo fully pathed filenames (unrooted) into tar
 - merge two docker execs into one docker exec
 - merge docker run and docker exec into one docker run


Tidy up entry/exit
------------------
Once there is a single tgz being piped into a single docker run
I can put helper functions into a 'library' .sh file which can
be sourced in cyber-dojo.sh
>>>>>>This can provide function to clean out report/ dir before cyber-dojo.sh runs
o) cyber_dojo_enter() ...
It can also provide
o) delete_files()
o) delete_dirs()
o) send_tgz() which can be renamed cyber_dojo_exit()
o) zip_sss()
o) zip_sandbox()
o) truncate_dont_extend()
o) is_truncated_text_file()
o) unrooted()
So main.sh will look like this:
    source #{CYBER_DOJO_LIB_SH_PATH}
    cyber_dojo_enter
    trap "cyber_dojo_exit" EXIT
    TMP_DIR=$(mktemp -d /tmp/XXXXXX)
    cd #{SANDBOX_DIR}
    bash ./cyber-dojo.sh \
           1> "${TMP_DIR}/stdout" \
           2> "${TMP_DIR}/stderr"
    echo $? > "${TMP_DIR}/status"


Ensuring container is stopped
-----------------------------
io-var-tar branch did this...
    tgz_out, timed_out = *docker_tar_pipe(tgz(files_in))
    begin
      files_out = truncated_untgz(tgz_out)
      ...
    rescue Zlib::GzipFile::Error
      ...
    end
    docker_stop_container
I think it would be better like this...
  tgz_out, timed_out = *docker_tar_pipe(tgz(files_in))
  docker_stop_container
  begin
    files_out = truncated_untgz(tgz_out)
    ...
  rescue Zlib::GzipFile::Error
    ...
  end
The docker-stop will flush its stdout. So spawned
process should then be able to read that on its stdin.
In fact, the docker-stop should be encapsulated inside
the docker_tar_pipe(tgz(files_in)) method. Yes, it did
that.
main docker-tar-pipe also did this...
    begin
      Timeout::timeout(max_seconds) {
        process.waitpid(pid) # [C]
      }
    rescue Timeout::Error
      timed_out = true
      docker_stop_container
      kill_process_group(pid)
    ensure
      tgz_out = pipe_close(r_stdout, w_stdout)
      stderr_out = pipe_close(r_stderr, w_stderr)
    end
This doesn't look right...
The kill_process_group(pid) call is before the calls
to read the pipes. Are the pipes tied to the
spawned process? Worth extracting some code (or using)
capture3_with_timeout.rb ?



readonly containers
-------------------
Make TMP-FS for /home/sandbox
Further, if the docker-run used --read-only it would mean
all LTFs were using /tmp and /sandbox only.
That would even make it possible to recycle containers.
You'd only really need to clear out /tmp and /sandbox.
They should be readonly anyway...
What happens to tests with --read-only added...
Only 2 failures
TrafficLightTest
9DB Ubuntu L23
9DD Ubuntu L41
Access to the path /home/sandbox/.mono is denied.
Need to make another tmp-fs for /home/sandbox
TMP_FS_HOME_DIR = "--tmpfs /home/sandbox:exec,size=50M,uid=#{UID},gid=#{GID}"
--read-only
And all pass :-)
Need to try on all LTFs

Image_name:TAG
--------------
  - will now acts as key for cache holding the rag-lambdas.

RAG Lambdas in Python
--------------------
  - visible_files can contain red_amber_green.rb !!!!!
    If present, and different to cached source, then could use it inside
    a runner call that uses Ruby image. This opens up the option of
    allowing lambdas in other languages. Eg Python. Based on the extension.
    And use a known python image.


SMALLER
=======
logger.warning()?
logger.info()?
logger.error()?

TarWriter has this...
  @writer.add_file_simple(filename, 0o644, size) do |fd|
  Perhaps I could set cyber-dojo.sh to +x automatically?
  Might allow a cleaner command line. Probably not.

rescue Errno::ESRCH ; 200; add logging

TGZ exception test ; 500; add StdoutWriter

create a custom BashStub which has methods for the specific bash calls...
      1) docker run --entrypoint=""
      2) docker exec to run cyber-dojo.sh
      3) docker exec to extract text files
      4) docker run --entrypoint=cat to get rag-lambda

uncomment multi_os_test '62B'  Robustness

uncomment c_assert_test 'AB6   RackDispatcher

Dispatcher test that mimics config.ru setup
  Use BashStub.
  Make 2 calls
  Verify stub only gets asked to cat ragfile from image once


---------------------------------------------------------------------

  class CustomBashStub
    def initialize
      @stubs = {}
    end
    def stub_docker_run(stdout, stderr, status)
      @stubs[:cyber_dojo_sh] = { stdout:stdout, stderr:stderr, status:status }
    end
    def stub_cyber_dojo_sh(stdout, stderr, status) # NO THIS IS Process.spawn()
      @stubs[:cyber_dojo_sh] = { stdout:stdout, stderr:stderr, status:status }
    end
    def stub_read_textfiles(tgz)
      @stubs[:tgz] = tgz
    end
    def stub_docker_cat(rag_lambda)
      @stubs[:rag_lambda] = rag_lambda
    end
    def assert(command)
      if command.include?('sleep')
        [@stdout,@stderr,@status]
      end
    end
    def exec(command)
    end
  end
